{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative, reproducible machine learning for structural biology\n",
    "##    Fergus Boyles and Fergus Imrie\n",
    "##    *Department of Statistics, University of Oxford*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But it runs on my machine!\n",
    "\n",
    "This notebook was written in Python 3.6 using numpy version 1.14.5, pandas version 0.23.1, and scikit-learn version 0.19.1. It will _probably_ run as long as your versions of these packages are reasonably up-to-date, but we can do better than that. Rather than provide a list of dependencies, hope you have the same versions, and pray that there are no conflicts between with your python installation, we're going to use the package manager Conda to set up an isolated python environment with exactly what we need. This has the twin benefits of not only ensuring you can run the code using exactly the same packages we used when writing it, but also ensures that any dependencies of our code can be installed without interfering with your default python installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Python environment for data science\n",
    "\n",
    "* numpy: Matrix algebra and numerical methods.\n",
    "* pandas: Data frames for manipulating and visualising data as tables.\n",
    "* matplotlib: Everybody's favourite Python plotting library.\n",
    "* seaborn: Statistical visualisation library built on matplotlib and pandas. Lots of high-level functions for data visualisation.\n",
    "* scikit-learn (sklearn): Machine learning library. Today we'll use its implementations of logistic regression and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sns.set(context='notebook', style='white', font_scale=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using existing code within a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import a .py file as a module as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can run the contents of a .py file in a cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run plotting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to build on existing code, we can load the contents of a .py file into a cell. We can then save our changes if we want to modify the original file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load plotting.py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, confusion_matrix\n",
    "\n",
    "def draw_roc_curve(y_true, y_score, annot=True, name=None, ax=None):\n",
    "    \"\"\"Draws a ROC (Receiver Operating Characteristic) curve using class rankings predicted by a classifier.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array-like): True class labels (0: negative; 1: positive)\n",
    "        y_score (array-like): Predicted probability of positive-class membership\n",
    "        annot (bool, optional): Whether to create and add a label to the curve with the computed AUC\n",
    "        name (str, optional): Name of the curve to add to the AUC label\n",
    "        ax (Matplotlib.Axes, optional): The axes on which to draw the ROC curve\n",
    "        \n",
    "    Returns:\n",
    "        ax (Matplotlib.Axes): The axes containing the ROC curve\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    # Add a label displaying the computed area under the curve\n",
    "    if annot:\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        if name is not None:\n",
    "            label = f'{name} AUC = {roc_auc:.3f}'\n",
    "        else:\n",
    "            label = f'AUC = {roc_auc:.3f}'\n",
    "    else:\n",
    "        label=None\n",
    "    \n",
    "    ax.plot(fpr, tpr, label=label)\n",
    "    ax.set_xlabel('False positive rate')\n",
    "    ax.set_ylabel('True positive rate')\n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def draw_confusion_matrix(y_true, y_predicted, class_labels=None, ax=None):\n",
    "    \"\"\"Draws a confusion matrix for classifier predictions.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array-like): True class labels\n",
    "        y_predicted (array-like): Predicted class labels\n",
    "        class_labels (dict-like, optional): Specify alternative names for each class to use for axis labels\n",
    "        ax (Matplotlib.Axes, optional): The axes on which to draw the confusion matrix\n",
    "        \n",
    "    Returns:\n",
    "        ax (Matplotlib.Axes): The axes containing the confusion matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_true, y_predicted)).T\n",
    "    \n",
    "    if class_labels is not None:\n",
    "        cm.rename(class_labels, axis='index', inplace=True)\n",
    "        cm.rename(class_labels, axis='columns', inplace=True)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', square=True, linewidths=0.1, linecolor='k', cbar_kws={'shrink': 0.75}, ax=ax)\n",
    "    ax.set_ylabel('Predicted class label')\n",
    "    ax.set_xlabel('True class label')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use all our usual IPython commands to explore our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.draw_confusion_matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read our data straight into a dataframe using Pandas. Jupyter renders dataframes as nice tables, allowing us to look at our data as soon as we load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../data/Data_3DSig.txt', sep=' ')\n",
    "all_data.dropna(axis='index', how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = pd.read_csv('../data/Data_Split.txt', sep=' ', header=None)\n",
    "split.columns = ['Protein', 'Split']\n",
    "\n",
    "# Select target-template pairs where both proteins belong to the 'same family' cluster\n",
    "targets = split[split['Split']=='FAMILY']['Protein']\n",
    "data = all_data[(all_data['Target'].isin(targets)) & (all_data['Template'].isin(targets))].copy()\n",
    "\n",
    "# Drop duplicated rows since we don't know which entry is correct\n",
    "\n",
    "# \n",
    "duplicate_idx = data.duplicated(subset=['Template', 'Target'], keep=False)\n",
    "duplicates = data.loc[duplicate_idx].sort_values(by=['Target', 'Template'])\n",
    "\n",
    "# \n",
    "data.drop_duplicates(subset=['Template', 'Target'], keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the plotting functions available through seaborn can operate directly on a pandas dataframe and use the row and column names to automatically annotate the plot. This is a very powerful way to rapidly visualise data during the exploration stage. Here we create a bar plot of the number of examples of each class in the data set, as data imbalance is an important consideration when training and testing a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "sns.countplot(data=data, x='Label', order=['Random', 'Fam', 'SFam', 'Fold'], ax=ax)\n",
    "fig.savefig('bars.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to focus on the toy problem of distinguishing between proteins that are in the same family and proteins that are completely unrelated. It's worth noting that pandas is not always clear about whether or not it is returning a view or a copy of the contents of a dataframe, so I'm explicitly creating a copy of the subset of the data we want. This lets us play with the data without modifying the original dataframe. In an interactive environment like Jupyter it pays to be careful when manipulating data and carefully document any changes made, as we want to take advatage of the ability to modify individual cells without re-running the entire notebook every time we make a change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_data = data[data['Label'].isin(['Fam', 'Random'])].copy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "sns.countplot(data=family_data, x='Label', order=['Random', 'Fam'], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our visualisation shows, the data set we'll be using has a good balance of examples of proteins from the same families and proteins that are unrelated, so we don't need to worry about data imbalance here. As in any machine learning project, it's important that we decide on our test set before going any further. We adopt an 80/20 split, using 80% of the data for training and reserving 20% for testing. For the workshop we're also using a subset of 5000 randomly-chosen proteins just to speed up model training. For this problem, we're splitting the data *by target* rather than simply splitting the examples to ensures that all examples for a target are in the same set.\n",
    "\n",
    "Also, for reproducibility, we set the seed for our random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "sample = np.random.choice(family_data['Target'].unique(), size=n_samples, replace=False)\n",
    "\n",
    "n_train = int(0.8*n_samples)\n",
    "n_test = int(0.2*n_samples)\n",
    "\n",
    "train = sample[:n_train]\n",
    "test = sample[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Target_Length', 'Template_Length', 'Contact_PPV', 'Contact_TP', 'Contact_P', 'Contact_All', 'Neff', 'SeqID']\n",
    "\n",
    "train_idx = family_data['Target'].isin(train)\n",
    "test_idx = family_data['Target'].isin(test)\n",
    "\n",
    "X_train = family_data[train_idx][feature_names].values\n",
    "X_test = family_data[test_idx][feature_names].values\n",
    "\n",
    "y_train = family_data[train_idx]['Label'].replace({'Random': 0, 'Fam': 1}).values\n",
    "y_test = family_data[test_idx]['Label'].replace({'Random': 0, 'Fam': 1}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that our training and test sets all have a similar balance of positive and negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.countplot(x=y_train, ax=axes[0])\n",
    "sns.countplot(x=y_test, ax=axes[1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy score: {rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rf.predict(X_test)\n",
    "test_probs = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plotting.draw_confusion_matrix(y_test, predicted, class_labels={0: 'Random', 1: 'Fam'}, ax=ax)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('rf_confusion_matrix.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C=1e5, random_state=42)\n",
    "logistic.fit(X_train, y_train)\n",
    "logistic_test_probs = logistic.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(f'Accuracy score: {logistic.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plotting.draw_roc_curve(y_test, test_probs, name='RF Test', ax=ax)\n",
    "#plotting.draw_roc_curve(y_test, logistic_test_probs, name='Logistic Test', ax=ax)\n",
    "#plotting.draw_roc_curve(y_test, logistic_test_probs_scaled, name='Logistic Test (scaled)', ax=ax)\n",
    "\n",
    "#ax.plot([0,1],[0,1], 'k--', label='Random classifier AUC = 0.5')\n",
    "ax.legend(loc='best')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('roc_curve.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logistic.fit(X_train_scaled, y_train)\n",
    "logistic_test_probs_scaled = logistic.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "print(f'Accuracy score: {logistic.score(X_test_scaled, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fergalicious]",
   "language": "python",
   "name": "conda-env-fergalicious-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
