{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative structural biology using machine learning and Jupyter notebook\n",
    "##    Fergus Boyles and Fergus Imrie\n",
    "##    *Department of Statistics, University of Oxford*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intro to conda\n",
    "* creating a new environment - show contents of environment file? show how to export an existing environment?\n",
    "* selecting a conda environment as an ipython kernel in jupyter\n",
    "* EXAMPLE: python 3 hello world using python2 and python2 kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But it runs on my machine!\n",
    "\n",
    "This notebook was written in Python 3.6 using numpy version 1.14.5, pandas version 0.23.1, and scikit-learn version 0.19.1. Rather than provide a list of dependencies, hope you have the same versions, and pray that there are no conflicts between with your python installation, we're going to use the package manager Conda to set up an isolated python environment with exactly what we need. This has the twin benefits of not only ensuring you can run the code using exactly the same packages we used when writing it, but also ensures that any dependencies of our code can be installed without interfering with your default python installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Python environment for data science\n",
    "\n",
    "* numpy: Matrix algebra and numerical methods.\n",
    "* pandas: Data frames for manipulating and visualising data as tables.\n",
    "* matplotlib: Everybody's favourite Python plotting library.\n",
    "* seaborn: Statistical visualisation library built on matplotlib and pandas. Lots of high-level functions for data visualisation.\n",
    "* scikit-learn (sklearn): Machine learning library. Today we'll use its implementations of logistic regression and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sns.set(context='notebook', style='white', font_scale=1.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep this notebook as short and tidy as possible, I've written some helper functions for thinks like plotting and data processing. Check out the other files if you'd like to see how things are implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Load and look:_ Can directly load data from csv using pandas. Don't forget to look at your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../data/Data_3DSig.txt', sep=' ')\n",
    "all_data.dropna(axis='index', how='any', inplace=True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = pd.read_csv('../data/Data_Split.txt', sep=' ', header=None)\n",
    "split.columns = ['Protein', 'Split']\n",
    "\n",
    "# Select target-template pairs where both proteins belong to the 'same family' cluster\n",
    "targets = split[split['Split']=='FAMILY']['Protein']\n",
    "data = all_data[(all_data['Target'].isin(targets)) & (all_data['Template'].isin(targets))].copy()\n",
    "\n",
    "# Drop duplicated rows since we don't know which entry is correct\n",
    "duplicate_idx = data.duplicated(subset=['Template', 'Target'], keep=False)\n",
    "duplicates = data.loc[duplicate_idx].sort_values(by=['Target', 'Template'])\n",
    "\n",
    "# could just directly call drop_duplicates if we don't want to keep a list of dropped rows\n",
    "data.drop_duplicates(subset=['Template', 'Target'], keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "sns.countplot(data=data, x='Label', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_data = data[data['Label'].isin(['Fam', 'Random'])].copy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "sns.countplot(data=family_data, x='Label', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is balanced so don't need to worry about any imbalance.\n",
    "\n",
    "Important that we decide train/test sets before we go any further. We adopt an 80/20 split. Note below that we sample a subset (5000) of the total number of proteins (10251). Also note that we're splitting *by target* rather than simply splitting the examples. This ensures that all examples for a target are in the same set.\n",
    "\n",
    "Also, for reproducibility, we set the seed for our random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "sample = np.random.choice(family_data['Target'].unique(), size=n_samples, replace=False)\n",
    "\n",
    "n_train = int(0.8*n_samples)\n",
    "n_test = int(0.2*n_samples)\n",
    "\n",
    "train = sample[:n_train]\n",
    "test = sample[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Target_Length', 'Template_Length', 'Contact_PPV', 'Contact_TP', 'Contact_P', 'Contact_All', 'Neff', 'SeqID']\n",
    "\n",
    "train_idx = family_data['Target'].isin(train)\n",
    "test_idx = family_data['Target'].isin(test)\n",
    "\n",
    "X_train = family_data[train_idx][feature_names].values\n",
    "X_test = family_data[test_idx][feature_names].values\n",
    "\n",
    "y_train = family_data[train_idx]['Label'].replace({'Random': 0, 'Fam': 1}).values\n",
    "y_test = family_data[test_idx]['Label'].replace({'Random': 0, 'Fam': 1}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that our training and test sets all have a similar balance of positive and negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.countplot(x=y_train, ax=axes[0])\n",
    "sns.countplot(x=y_test, ax=axes[1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy score: {rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rf.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plotting.draw_confusion_matrix(y_test, predicted, ['Random', 'Fam'], ax=ax)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('rf_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will initially be absent\n",
    "# show cm/roc curve, then ask \"what if we want to try another classifier and compare it to our random forest?\"\n",
    "# illustrates how we can add a new cell anywhere and update our plots as we go along\n",
    "\n",
    "logistic = LogisticRegression(C=1e5, random_state=42)\n",
    "logistic.fit(X_train, y_train)\n",
    "print(f'Accuracy score: {logistic.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# initially absent\n",
    "logistic_test_probs = logistic.predict_proba(X_test)[:,1]\n",
    "\n",
    "# initially don't show result of testing on the training set\n",
    "#train_probs = rf.predict_proba(X_train)[:,1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plotting.draw_roc_curve(y_test, test_probs, name='RF Test', ax=ax)\n",
    "plotting.draw_roc_curve(y_test, logistic_test_probs, name='Logistic Test', ax=ax)\n",
    "#plotting.draw_roc_curve(y_train, train_probs, name='RF Train', ax=ax)\n",
    "ax.plot([0,1],[0,1], 'k--', label='Random classifier AUC = 0.5')\n",
    "ax.legend(loc='best')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('roc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fergalicious]",
   "language": "python",
   "name": "conda-env-fergalicious-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
